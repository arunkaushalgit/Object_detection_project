import streamlit as st
from PIL import Image
import numpy as np
import cv2
import tempfile
import sys
import os

# Add root directory to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from inference.visualization import detect_objects, draw_boxes, model

# from inference.visualization import detect_objects, draw_boxes , model # <-- ðŸ”— Use modular code

st.set_page_config(page_title="YOLOv8 Detection", layout="wide")

st.title("Object Detection App")
st.markdown("Detect objects from **Image**, **Video**, or **Webcam**.")

# Sidebar Settings
st.sidebar.title("âš™ï¸ Settings")
conf_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 1.0, 0.5, 0.05)
mode = st.sidebar.radio("Select Mode", ["Image", "Video", "Webcam"])

# Image Mode
if mode == "Image":
    uploaded_file = st.sidebar.file_uploader("ðŸ“¤ Upload Image", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file).convert("RGB")
        img_np = np.array(image)

        results = detect_objects(img_np, conf=conf_threshold)
        img_draw, detections = draw_boxes(img_np, results)

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ðŸ–¼ï¸ Original Image")
            st.image(image, use_container_width=True)
        with col2:
            st.subheader("ðŸŽ¯ Detected Image")
            st.image(img_draw, use_container_width=True)

        if detections:
            st.markdown("### ðŸ“Š Detection Summary")
            st.dataframe(detections, use_container_width=True)
        else:
            st.info("No objects detected.")

# Video Mode
elif mode == "Video":
    uploaded_video = st.sidebar.file_uploader("ðŸ“¤ Upload Video", type=["mp4", "avi", "mov"])
    if uploaded_video:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())

        cap = cv2.VideoCapture(tfile.name)
        stframe = st.empty()
        st.markdown("### ðŸ“½ï¸ Processing Video...")

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model(frame, conf=conf_threshold)[0]
            img_draw, _ = draw_boxes(frame, results)
            img_rgb = cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB)
            stframe.image(img_rgb, channels="RGB", use_container_width=True)

        cap.release()

# Webcam Mode
elif mode == "Webcam":
    stframe = st.empty()
    st.markdown("### ðŸŽ¥ Live Webcam Detection")

    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        if not ret:
            st.warning("âš ï¸ Webcam not accessible.")
            break

        results = model(frame, conf=conf_threshold)[0]
        img_draw, _ = draw_boxes(frame, results)
        img_rgb = cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB)
        stframe.image(img_rgb, channels="RGB", use_container_width=True)

        # if st.sidebar.button("ðŸ”´ Stop Webcam"):
        #     break

    cap.release()
